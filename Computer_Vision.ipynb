{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Computer_Vision.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyNrnzBahDjYtYEpZOxFElxM",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/patzaa/Pytorch-ML/blob/main/Computer_Vision.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rf-4sdIRGNxn"
      },
      "source": [
        "# Computer Vision Skeleton\n",
        "\n",
        "Classifing clothes using supervised learning on FashionMNIST Dataset:\n",
        "\n",
        "*   ```Model Class``` \n",
        "*   ```Train Loop```\n",
        "*   ```Test Loop```\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XsNRHXB03QEp"
      },
      "source": [
        "import torch\n",
        "from torch import nn\n",
        "from torch.utils.data import DataLoader\n",
        "from torchvision import datasets\n",
        "from torchvision.transforms import ToTensor, Lambda\n",
        "\n",
        "class FashionCNN(nn.Module):\n",
        "    \n",
        "    def __init__(self):\n",
        "        super(FashionCNN, self).__init__()\n",
        "        \n",
        "        self.layer1 = nn.Sequential(\n",
        "            nn.Conv2d(in_channels=1, out_channels=32, kernel_size=3, padding=1),\n",
        "            nn.BatchNorm2d(32),\n",
        "            nn.ReLU(),\n",
        "            nn.MaxPool2d(kernel_size=2, stride=2)\n",
        "        )\n",
        "        \n",
        "        self.layer2 = nn.Sequential(\n",
        "            nn.Conv2d(in_channels=32, out_channels=64, kernel_size=3),\n",
        "            nn.BatchNorm2d(64),\n",
        "            nn.ReLU(),\n",
        "            nn.MaxPool2d(2)\n",
        "        )\n",
        "        \n",
        "        self.fc1 = nn.Linear(in_features=64*6*6, out_features=600)\n",
        "        self.drop = nn.Dropout2d(0.25)\n",
        "        self.fc2 = nn.Linear(in_features=600, out_features=120)\n",
        "        self.fc3 = nn.Linear(in_features=120, out_features=10)\n",
        "        \n",
        "    def forward(self, x):\n",
        "        out = self.layer1(x)\n",
        "        out = self.layer2(out)\n",
        "        out = out.view(out.size(0), -1)\n",
        "        out = self.fc1(out)\n",
        "        out = self.drop(out)\n",
        "        out = self.fc2(out)\n",
        "        out = self.fc3(out)\n",
        "        \n",
        "        return out\n",
        "\n",
        "training_data = datasets.FashionMNIST(\n",
        "    root=\"data\",\n",
        "    train=True,\n",
        "    download=True,\n",
        "    transform=ToTensor()\n",
        ")\n",
        "\n",
        "test_data = datasets.FashionMNIST(\n",
        "    root=\"data\",\n",
        "    train=False,\n",
        "    download=True,\n",
        "    transform=ToTensor()\n",
        ")\n",
        "\n",
        "\n",
        "train_dataloader = DataLoader(training_data, batch_size=64)\n",
        "test_dataloader = DataLoader(test_data, batch_size=64)\n"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2dSNr0Tv45yq"
      },
      "source": [
        "def training_loop(dataloader, model, loss_fn, optimizer): \n",
        "\n",
        "  size = len(dataloader.dataset)\n",
        "\n",
        "  for batch, (x, y) in enumerate(dataloader):\n",
        "    \n",
        "    #compute prediction and loss\n",
        "    pred = model(x)\n",
        "    loss = loss_fn(pred,y)\n",
        "\n",
        "    # Backprop\n",
        "    optimizer.zero_grad()\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "\n",
        "    if batch % 100 == 0:\n",
        "      loss, current = loss.item(),  batch * len(x)\n",
        "      print(f\"loss: {loss:>7f}  [{current:>5d}/{size:>5d}]\")\n",
        "\n",
        "def eval_loop(dataloader, model, loss_fn):\n",
        "    size = len(dataloader.dataset)\n",
        "    test_loss, correct = 0, 0\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for X, y in dataloader:\n",
        "            pred = model(X)\n",
        "            test_loss += loss_fn(pred, y).item()\n",
        "            correct += (pred.argmax(1) == y).type(torch.float).sum().item()\n",
        "\n",
        "    test_loss /= size\n",
        "    correct /= size\n",
        "    print(f\"Test Error: \\n Accuracy: {(100*correct):>0.1f}%, Avg loss: {test_loss:>8f} \\n\")\n"
      ],
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YfjZVdv_DK0S",
        "outputId": "7bd9651c-00f0-4688-87bb-c954bdac13b3"
      },
      "source": [
        "LR = 1e-3\n",
        "EPOCH = 20\n",
        "\n",
        "model = FeedForward()\n",
        "\n",
        "#define loss function and optimizer\n",
        "loss_fn = nn.CrossEntropyLoss()\n",
        "optimizer = torch.optim.SGD(model.parameters(), lr=LR)\n",
        "\n",
        "\n",
        "for t in range(EPOCH):\n",
        "    print(f\"Epoch {t+1}\\n-------------------------------\")\n",
        "    training_loop(train_dataloader, model, loss_fn, optimizer)\n",
        "    eval_loop(test_dataloader, model, loss_fn)\n",
        "print(\"Done training!\")"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1\n",
            "-------------------------------\n",
            "loss: 2.305161  [    0/60000]\n",
            "loss: 2.300931  [ 6400/60000]\n",
            "loss: 2.289136  [12800/60000]\n",
            "loss: 2.279658  [19200/60000]\n",
            "loss: 2.287672  [25600/60000]\n",
            "loss: 2.268106  [32000/60000]\n",
            "loss: 2.279979  [38400/60000]\n",
            "loss: 2.270305  [44800/60000]\n",
            "loss: 2.268209  [51200/60000]\n",
            "loss: 2.237894  [57600/60000]\n",
            "Test Error: \n",
            " Accuracy: 30.6%, Avg loss: 0.035235 \n",
            "\n",
            "Epoch 2\n",
            "-------------------------------\n",
            "loss: 2.270222  [    0/60000]\n",
            "loss: 2.274974  [ 6400/60000]\n",
            "loss: 2.237896  [12800/60000]\n",
            "loss: 2.216947  [19200/60000]\n",
            "loss: 2.245202  [25600/60000]\n",
            "loss: 2.207590  [32000/60000]\n",
            "loss: 2.223502  [38400/60000]\n",
            "loss: 2.211525  [44800/60000]\n",
            "loss: 2.209713  [51200/60000]\n",
            "loss: 2.133419  [57600/60000]\n",
            "Test Error: \n",
            " Accuracy: 31.9%, Avg loss: 0.033923 \n",
            "\n",
            "Epoch 3\n",
            "-------------------------------\n",
            "loss: 2.223890  [    0/60000]\n",
            "loss: 2.228690  [ 6400/60000]\n",
            "loss: 2.159470  [12800/60000]\n",
            "loss: 2.101949  [19200/60000]\n",
            "loss: 2.168039  [25600/60000]\n",
            "loss: 2.122133  [32000/60000]\n",
            "loss: 2.118302  [38400/60000]\n",
            "loss: 2.118341  [44800/60000]\n",
            "loss: 2.123589  [51200/60000]\n",
            "loss: 1.976875  [57600/60000]\n",
            "Test Error: \n",
            " Accuracy: 33.5%, Avg loss: 0.032006 \n",
            "\n",
            "Epoch 4\n",
            "-------------------------------\n",
            "loss: 2.159039  [    0/60000]\n",
            "loss: 2.159673  [ 6400/60000]\n",
            "loss: 2.052831  [12800/60000]\n",
            "loss: 1.948801  [19200/60000]\n",
            "loss: 2.070946  [25600/60000]\n",
            "loss: 2.021355  [32000/60000]\n",
            "loss: 1.990972  [38400/60000]\n",
            "loss: 2.010962  [44800/60000]\n",
            "loss: 2.027061  [51200/60000]\n",
            "loss: 1.804604  [57600/60000]\n",
            "Test Error: \n",
            " Accuracy: 41.4%, Avg loss: 0.030039 \n",
            "\n",
            "Epoch 5\n",
            "-------------------------------\n",
            "loss: 2.092289  [    0/60000]\n",
            "loss: 2.089149  [ 6400/60000]\n",
            "loss: 1.952213  [12800/60000]\n",
            "loss: 1.805402  [19200/60000]\n",
            "loss: 1.985781  [25600/60000]\n",
            "loss: 1.930962  [32000/60000]\n",
            "loss: 1.875753  [38400/60000]\n",
            "loss: 1.918213  [44800/60000]\n",
            "loss: 1.940017  [51200/60000]\n",
            "loss: 1.660207  [57600/60000]\n",
            "Test Error: \n",
            " Accuracy: 44.1%, Avg loss: 0.028442 \n",
            "\n",
            "Epoch 6\n",
            "-------------------------------\n",
            "loss: 2.022649  [    0/60000]\n",
            "loss: 2.021983  [ 6400/60000]\n",
            "loss: 1.864530  [12800/60000]\n",
            "loss: 1.693988  [19200/60000]\n",
            "loss: 1.909074  [25600/60000]\n",
            "loss: 1.850331  [32000/60000]\n",
            "loss: 1.774309  [38400/60000]\n",
            "loss: 1.834663  [44800/60000]\n",
            "loss: 1.862197  [51200/60000]\n",
            "loss: 1.544750  [57600/60000]\n",
            "Test Error: \n",
            " Accuracy: 44.9%, Avg loss: 0.027082 \n",
            "\n",
            "Epoch 7\n",
            "-------------------------------\n",
            "loss: 1.949517  [    0/60000]\n",
            "loss: 1.954352  [ 6400/60000]\n",
            "loss: 1.780613  [12800/60000]\n",
            "loss: 1.604916  [19200/60000]\n",
            "loss: 1.837231  [25600/60000]\n",
            "loss: 1.772891  [32000/60000]\n",
            "loss: 1.685213  [38400/60000]\n",
            "loss: 1.757667  [44800/60000]\n",
            "loss: 1.796558  [51200/60000]\n",
            "loss: 1.450479  [57600/60000]\n",
            "Test Error: \n",
            " Accuracy: 45.2%, Avg loss: 0.025931 \n",
            "\n",
            "Epoch 8\n",
            "-------------------------------\n",
            "loss: 1.881139  [    0/60000]\n",
            "loss: 1.891886  [ 6400/60000]\n",
            "loss: 1.703432  [12800/60000]\n",
            "loss: 1.534490  [19200/60000]\n",
            "loss: 1.779744  [25600/60000]\n",
            "loss: 1.704760  [32000/60000]\n",
            "loss: 1.612381  [38400/60000]\n",
            "loss: 1.694546  [44800/60000]\n",
            "loss: 1.746405  [51200/60000]\n",
            "loss: 1.377018  [57600/60000]\n",
            "Test Error: \n",
            " Accuracy: 45.4%, Avg loss: 0.025048 \n",
            "\n",
            "Epoch 9\n",
            "-------------------------------\n",
            "loss: 1.826374  [    0/60000]\n",
            "loss: 1.844878  [ 6400/60000]\n",
            "loss: 1.640962  [12800/60000]\n",
            "loss: 1.481366  [19200/60000]\n",
            "loss: 1.739813  [25600/60000]\n",
            "loss: 1.652240  [32000/60000]\n",
            "loss: 1.558992  [38400/60000]\n",
            "loss: 1.648318  [44800/60000]\n",
            "loss: 1.710583  [51200/60000]\n",
            "loss: 1.325047  [57600/60000]\n",
            "Test Error: \n",
            " Accuracy: 45.6%, Avg loss: 0.024411 \n",
            "\n",
            "Epoch 10\n",
            "-------------------------------\n",
            "loss: 1.783051  [    0/60000]\n",
            "loss: 1.811821  [ 6400/60000]\n",
            "loss: 1.594562  [12800/60000]\n",
            "loss: 1.442476  [19200/60000]\n",
            "loss: 1.712515  [25600/60000]\n",
            "loss: 1.614565  [32000/60000]\n",
            "loss: 1.519456  [38400/60000]\n",
            "loss: 1.616082  [44800/60000]\n",
            "loss: 1.683888  [51200/60000]\n",
            "loss: 1.287362  [57600/60000]\n",
            "Test Error: \n",
            " Accuracy: 45.7%, Avg loss: 0.023947 \n",
            "\n",
            "Epoch 11\n",
            "-------------------------------\n",
            "loss: 1.748272  [    0/60000]\n",
            "loss: 1.787221  [ 6400/60000]\n",
            "loss: 1.559598  [12800/60000]\n",
            "loss: 1.413488  [19200/60000]\n",
            "loss: 1.692909  [25600/60000]\n",
            "loss: 1.586617  [32000/60000]\n",
            "loss: 1.489388  [38400/60000]\n",
            "loss: 1.592264  [44800/60000]\n",
            "loss: 1.662719  [51200/60000]\n",
            "loss: 1.258203  [57600/60000]\n",
            "Test Error: \n",
            " Accuracy: 46.0%, Avg loss: 0.023592 \n",
            "\n",
            "Epoch 12\n",
            "-------------------------------\n",
            "loss: 1.718925  [    0/60000]\n",
            "loss: 1.767764  [ 6400/60000]\n",
            "loss: 1.531986  [12800/60000]\n",
            "loss: 1.391239  [19200/60000]\n",
            "loss: 1.676861  [25600/60000]\n",
            "loss: 1.564676  [32000/60000]\n",
            "loss: 1.465371  [38400/60000]\n",
            "loss: 1.573907  [44800/60000]\n",
            "loss: 1.645834  [51200/60000]\n",
            "loss: 1.234868  [57600/60000]\n",
            "Test Error: \n",
            " Accuracy: 46.4%, Avg loss: 0.023309 \n",
            "\n",
            "Epoch 13\n",
            "-------------------------------\n",
            "loss: 1.694268  [    0/60000]\n",
            "loss: 1.751837  [ 6400/60000]\n",
            "loss: 1.510233  [12800/60000]\n",
            "loss: 1.372797  [19200/60000]\n",
            "loss: 1.663563  [25600/60000]\n",
            "loss: 1.547246  [32000/60000]\n",
            "loss: 1.445103  [38400/60000]\n",
            "loss: 1.559044  [44800/60000]\n",
            "loss: 1.632355  [51200/60000]\n",
            "loss: 1.214654  [57600/60000]\n",
            "Test Error: \n",
            " Accuracy: 46.9%, Avg loss: 0.023076 \n",
            "\n",
            "Epoch 14\n",
            "-------------------------------\n",
            "loss: 1.673110  [    0/60000]\n",
            "loss: 1.738070  [ 6400/60000]\n",
            "loss: 1.492401  [12800/60000]\n",
            "loss: 1.357072  [19200/60000]\n",
            "loss: 1.652557  [25600/60000]\n",
            "loss: 1.533124  [32000/60000]\n",
            "loss: 1.428330  [38400/60000]\n",
            "loss: 1.546726  [44800/60000]\n",
            "loss: 1.620493  [51200/60000]\n",
            "loss: 1.197264  [57600/60000]\n",
            "Test Error: \n",
            " Accuracy: 47.6%, Avg loss: 0.022878 \n",
            "\n",
            "Epoch 15\n",
            "-------------------------------\n",
            "loss: 1.654458  [    0/60000]\n",
            "loss: 1.725999  [ 6400/60000]\n",
            "loss: 1.477336  [12800/60000]\n",
            "loss: 1.343318  [19200/60000]\n",
            "loss: 1.643457  [25600/60000]\n",
            "loss: 1.521026  [32000/60000]\n",
            "loss: 1.413614  [38400/60000]\n",
            "loss: 1.536541  [44800/60000]\n",
            "loss: 1.610953  [51200/60000]\n",
            "loss: 1.181597  [57600/60000]\n",
            "Test Error: \n",
            " Accuracy: 48.1%, Avg loss: 0.022706 \n",
            "\n",
            "Epoch 16\n",
            "-------------------------------\n",
            "loss: 1.638237  [    0/60000]\n",
            "loss: 1.715218  [ 6400/60000]\n",
            "loss: 1.464378  [12800/60000]\n",
            "loss: 1.331113  [19200/60000]\n",
            "loss: 1.635934  [25600/60000]\n",
            "loss: 1.510828  [32000/60000]\n",
            "loss: 1.401024  [38400/60000]\n",
            "loss: 1.527881  [44800/60000]\n",
            "loss: 1.602707  [51200/60000]\n",
            "loss: 1.167903  [57600/60000]\n",
            "Test Error: \n",
            " Accuracy: 48.6%, Avg loss: 0.022553 \n",
            "\n",
            "Epoch 17\n",
            "-------------------------------\n",
            "loss: 1.623798  [    0/60000]\n",
            "loss: 1.705137  [ 6400/60000]\n",
            "loss: 1.453343  [12800/60000]\n",
            "loss: 1.320190  [19200/60000]\n",
            "loss: 1.629586  [25600/60000]\n",
            "loss: 1.502164  [32000/60000]\n",
            "loss: 1.389951  [38400/60000]\n",
            "loss: 1.520407  [44800/60000]\n",
            "loss: 1.596095  [51200/60000]\n",
            "loss: 1.155250  [57600/60000]\n",
            "Test Error: \n",
            " Accuracy: 49.2%, Avg loss: 0.022415 \n",
            "\n",
            "Epoch 18\n",
            "-------------------------------\n",
            "loss: 1.610948  [    0/60000]\n",
            "loss: 1.695419  [ 6400/60000]\n",
            "loss: 1.443528  [12800/60000]\n",
            "loss: 1.310250  [19200/60000]\n",
            "loss: 1.623748  [25600/60000]\n",
            "loss: 1.494792  [32000/60000]\n",
            "loss: 1.379848  [38400/60000]\n",
            "loss: 1.514080  [44800/60000]\n",
            "loss: 1.590239  [51200/60000]\n",
            "loss: 1.143628  [57600/60000]\n",
            "Test Error: \n",
            " Accuracy: 49.8%, Avg loss: 0.022288 \n",
            "\n",
            "Epoch 19\n",
            "-------------------------------\n",
            "loss: 1.599259  [    0/60000]\n",
            "loss: 1.686288  [ 6400/60000]\n",
            "loss: 1.434921  [12800/60000]\n",
            "loss: 1.301091  [19200/60000]\n",
            "loss: 1.618556  [25600/60000]\n",
            "loss: 1.487629  [32000/60000]\n",
            "loss: 1.370458  [38400/60000]\n",
            "loss: 1.508379  [44800/60000]\n",
            "loss: 1.585370  [51200/60000]\n",
            "loss: 1.133234  [57600/60000]\n",
            "Test Error: \n",
            " Accuracy: 50.3%, Avg loss: 0.022171 \n",
            "\n",
            "Epoch 20\n",
            "-------------------------------\n",
            "loss: 1.588512  [    0/60000]\n",
            "loss: 1.677647  [ 6400/60000]\n",
            "loss: 1.427578  [12800/60000]\n",
            "loss: 1.292715  [19200/60000]\n",
            "loss: 1.613878  [25600/60000]\n",
            "loss: 1.481173  [32000/60000]\n",
            "loss: 1.361691  [38400/60000]\n",
            "loss: 1.503183  [44800/60000]\n",
            "loss: 1.581172  [51200/60000]\n",
            "loss: 1.123651  [57600/60000]\n",
            "Test Error: \n",
            " Accuracy: 50.8%, Avg loss: 0.022062 \n",
            "\n",
            "Done training!\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}